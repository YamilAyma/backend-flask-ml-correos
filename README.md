# ğŸ“¬ Backend Flask ML Correos
> Backend Flask ML Correos es un servicio backend desarrollado con Flask que proporciona funcionalidades de predicciÃ³n utilizando un modelo de Machine Learning. Este backend estÃ¡ diseÃ±ado para integrarse con un frontend, pero tambiÃ©n puede operar de manera independiente.



# ğŸš€ CaracterÃ­sticas
- PredicciÃ³n de Correos: Clasifica correos electrÃ³nicos utilizando un modelo de Machine Learning.
- IntegraciÃ³n con Transformers: Utiliza modelos preentrenados de la biblioteca transformers.
- CORS habilitado: Permite solicitudes desde diferentes dominios, facilitando la integraciÃ³n con frontends.

# ğŸ› ï¸ TecnologÃ­as Utilizadas
- Flask: Microframework web para Python.
- Transformers: Biblioteca de modelos de Machine Learning de Hugging Face.
- Flask-CORS: ExtensiÃ³n para habilitar CORS en Flask.


# ğŸ“ Estructura del Proyecto
```
backend-flask-ml-correos/
â”œâ”€â”€ model/
â”‚  â”œâ”€â”€ config.json
â”‚  â”œâ”€â”€ model.safetensors
â”‚  â””â”€â”€ tokenizer_config.json
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ gunicorn.conf.py
â”œâ”€â”€ build.sh
â”œâ”€â”€ start.sh
â””â”€â”€ README.md
```



# âš™ï¸ ConfiguraciÃ³n y EjecuciÃ³n en Entorno Local
1. Clonar el Repositorio
```
git clone https://github.com/YamilAyma/backend-flask-ml-correos.git
cd backend-flask-ml-correos
```

2. Crear y Activar un **Entorno Virtual**
```
python -m venv venv
source venv/bin/activate # En Windows: venv\Scripts\activate
```


3. Instalar Dependencias
```
pip install -r requirements.txt
```

4. Ejecutar la AplicaciÃ³n
```
python main.py
```

La aplicaciÃ³n estarÃ¡ disponible en http://127.0.0.1:5000/.


# ğŸ“¬ Endpoints Disponibles
POST /predict: Recibe datos de entrada JSON con Ã¹nicamente un valor a enviar ("email") y devuelve la predicciÃ³n del modelo.


# ğŸ“ Notas Adicionales
AsegÃºrate de que los archivos del modelo (config.json, model.safetensors, tokenizer_config.json) estÃ©n correctamente ubicados en la carpeta model/.

**Este backend estÃ¡ configurado para su despliegue en Render, pero las instrucciones proporcionadas aquÃ­ estÃ¡n adaptadas para su ejecuciÃ³n en un entorno local.**

Para pruebas y desarrollo, se recomienda utilizar el entorno local antes de proceder al despliegue en producciÃ³n.


---
# Acerca del modelo ğŸ¤–
** âš™ config.json**: Este archivo contiene la configuraciÃ³n del modelo, incluyendo la arquitectura, el nÃºmero de capas, el tamaÃ±o de los embeddings, etc. Es esencial para que la librerÃ­a transformers pueda cargar el modelo correctamente.

**ğŸ”¢ model.safetensors**: Este archivo contiene los pesos del modelo, es decir, los valores numÃ©ricos que el modelo ha aprendido durante el entrenamiento. La extensiÃ³n .safetensors indica que los pesos estÃ¡n guardados en un formato seguro y eficiente.

**âš™â–¶ğŸ”¢ tokenizer_config.json**: Este archivo contiene informaciÃ³n sobre cÃ³mo se tokeniza el texto de entrada, incluyendo el vocabulario, los tokens especiales y otros parÃ¡metros de configuraciÃ³n.

**ğŸ“— tokenizer.json**: Contiene toda la configuraciÃ³n necesaria para tokenizar el texto.

**ğŸ“š vocab.txt**: Este archivo contiene el vocabulario del tokenizador, es decir, la lista de todas las palabras y subpalabras que el tokenizador reconoce. Si estÃ¡s usando un tokenizador mÃ¡s avanzado, es posible que tengas otros archivos de vocabulario en lugar de vocab.txt.

**â„¹ special_tokens_map.json**: Este archivo define los tokens especiales que utiliza el tokenizador, como el token de inicio de secuencia ([CLS]), el token de fin de secuencia ([SEP]), el token de relleno ([PAD]) y el token de desconocido ([UNK]).
